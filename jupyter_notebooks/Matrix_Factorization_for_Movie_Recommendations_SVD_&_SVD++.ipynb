{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alaeddinehamroun/Recommender-Systems/blob/main/Matrix_Factorization_for_Movie_Recommendations_SVD_%26_SVD%2B%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I5DYrj4v_r2_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHCxepII_r3S",
        "outputId": "81b58c9b-252e-461e-bc53-1cc4c7763241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-surprise) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-surprise) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-surprise) (1.10.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp39-cp39-linux_x86_64.whl size=3195797 sha256=cca8ef8d58ff4b8b2efa34fbc68983dfdc32bcfbe25719c7ef9b5e1ed738f3aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/3a/46/9b17b3512bdf283c6cb84f59929cdd5199d4e754d596d22784\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.3\n"
          ]
        }
      ],
      "source": [
        "# Why surprise? primarily because it implements SVD++\n",
        "# Surprise is a Python scikit for building and analyzing recommender systems that deal with explicit rating data.\n",
        "!pip install scikit-surprise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpO7CDQl_r3R"
      },
      "source": [
        "# Matrix Factorization\n",
        "\n",
        "Matrix factorization is a popular technique used in machine learning and recommender systems for reducing the dimensionality of a large matrix by decomposing it into two or more lower-dimensional matrices. In the context of recommender systems, the large matrix represents the user-item rating matrix, where each cell of the matrix corresponds to a user's rating of a particular item.\n",
        "\n",
        "Matrix factorization algorithms seek to factorize this matrix into two matrices - one that describes the users and the other that describes the items - such that the product of these matrices approximates the original matrix. The factors in these matrices can be interpreted as user and item features, which can be used to predict missing ratings or recommend items to users.\n",
        "\n",
        "There are several matrix factorization algorithms, including Singular Value Decomposition (SVD), Non-negative Matrix Factorization (NMF), and Alternating Least Squares (ALS). These algorithms differ in their approach to matrix factorization, with some focusing on minimizing the error between the predicted and actual ratings, while others incorporate regularization to prevent overfitting or bias.\n",
        "\n",
        "Matrix factorization has been shown to be an effective technique for dealing with the sparsity and scalability challenges in recommender systems, making it a popular approach in industry and academia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYCbCF8D_r3S"
      },
      "source": [
        "## Imports & utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "44U5wSlW_r3S"
      },
      "outputs": [],
      "source": [
        "from surprise import Dataset # To load the dataset.\n",
        "from surprise import Reader  # To parse a file containing ratings.\n",
        "                             # Such a file is assumed to specify only one rating per line,\n",
        "                             # and each line needs to respect the following structure:\n",
        "                             # user; item; rating; [timestamp]\n",
        "from surprise import SVD, SVDpp\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import LeaveOneOut\n",
        "from surprise import KNNBaseline\n",
        "\n",
        "from collections import defaultdict\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cJ6Z27mej6Pw"
      },
      "outputs": [],
      "source": [
        "def getTopN(predictions, n=10, minimumRating=4.0):\n",
        "    \"\"\"\n",
        "    Top N recommendations based on predictions\n",
        "  \n",
        "    Args:\n",
        "        predictions:\n",
        "        n:\n",
        "        minimumRating: \n",
        "    Returns:\n",
        "        dict: The top N rated movies for each userId\n",
        "    \"\"\"\n",
        "    # Create a dictionary of empty lists\n",
        "    topN = defaultdict(list)\n",
        "    # Loop through each prediction tuple and append movieId and estimatedRating to the corresponding userId in topN\n",
        "    for userId, movieId, actualRating, estimatedRating, _ in predictions:\n",
        "        if (estimatedRating >= minimumRating):\n",
        "            topN[int(userId)].append((int(movieId), estimatedRating))\n",
        "    # For each userId in topN, sort the list of movie ratings by the estimated rating in descending order\n",
        "    # and keep only the top n rated movies.\n",
        "    for userId, ratings in topN.items():\n",
        "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        topN[int(userId)] = ratings[:n]\n",
        "\n",
        "    return topN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getPopularityRanks(data):\n",
        "    \"\"\"\n",
        "    Compute the popularity ranks\n",
        "    Params:\n",
        "        data: list of ratings\n",
        "    \"\"\"\n",
        "    ratings = defaultdict(int)\n",
        "    rankings = defaultdict(int)\n",
        "    for row in data:\n",
        "      movieID = int(row[1])\n",
        "      ratings[movieID] += 1\n",
        "    rank = 1\n",
        "    for movieID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
        "        rankings[movieID] = rank\n",
        "        rank += 1\n",
        "    return rankings    "
      ],
      "metadata": {
        "id": "v--UDffnTpTj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation metrics\n",
        "\n",
        "* **Metrics for evaluating model accuracy**\n",
        "  * **RMSE**: Root Mean Squared Error. Lower values mean better accuracy.\n",
        "  * **MAE**: Mean Absolute Error. Lower values mean better accuracy.\n",
        "  \n",
        "  \n",
        "* **Metrics for evaluating top end recommendations**\n",
        "    * **Hit Rate (HR)**: How often we are able to recommend a left-out rating. Higher is better.\n",
        "    * **Cumulative Hit Rate (cHR)**: Hit rate, confined to ratings above a certain threshold. Higher is better.\n",
        "    * **Average Reciprocal Hit Rank (ARHR)**: Hit rate that takes the ranking into account. Higher is better.\n",
        "    * **Coverage**: Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\n",
        "    * **Diversity**: 1-S, where S is the average similarity score between every possible pair of recommendations for a given user. Higher means more diverse.\n",
        "    * **Novelty**: Average popularity rank of recommended items. Higher means more novel."
      ],
      "metadata": {
        "id": "wK2WY3vcwpb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Recommender metrics utils:"
      ],
      "metadata": {
        "id": "vgkSpQI06gHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hit Rate\n",
        "def hitRate(topNPredicted, leftOutPredictions):\n",
        "    \"\"\"\n",
        "    The hit rate for a set of top N recommendations and left out predictions\n",
        "    \n",
        "    Args:\n",
        "        topNPredicted: Top 10 recommendations per user.\n",
        "        lefOutPredictions: Predicted ratings for left-out set: this set is composed of one rating per user.\n",
        "    \n",
        "    Returns:\n",
        "        float: The hit rate.\n",
        "    \"\"\"\n",
        "    \n",
        "    hits = 0\n",
        "    total = 0\n",
        "    \n",
        "    # for each left-out rating\n",
        "    for leftOut in leftOutPredictions:\n",
        "        userId = leftOut[0]\n",
        "        leftOutMovieId = leftOut[1]\n",
        "        # is it in the predicted top 10 for this user?\n",
        "        hit = False\n",
        "        for movieId, predictedRating in topNPredicted[int(userId)]:\n",
        "            if (int(leftOutMovieId) == int(movieId)):\n",
        "                hit = True\n",
        "                break\n",
        "        if (hit):\n",
        "            hits +=1\n",
        "        total +=1\n",
        "        \n",
        "    return hits/total"
      ],
      "metadata": {
        "id": "LhUQf00gr0OU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CumulativeHitRate(topNPredicted, leftOutPredictions, ratingCutoff=0):\n",
        "    hits = 0\n",
        "    total = 0\n",
        "\n",
        "    # For each left-out rating\n",
        "    for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "        # Only look at ability to recommend things the users actually liked...\n",
        "        if (actualRating >= ratingCutoff):\n",
        "            # Is it in the predicted top 10 for this user?\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                if (int(leftOutMovieID) == movieID):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit) :\n",
        "                hits += 1\n",
        "\n",
        "            total += 1\n",
        "\n",
        "    # Compute overall precision\n",
        "    return hits/total"
      ],
      "metadata": {
        "id": "WpJj2FZx6l90"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AverageReciprocalHitRank(topNPredicted, leftOutPredictions):\n",
        "    summation = 0\n",
        "    total = 0\n",
        "    # For each left-out rating\n",
        "    for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "        # Is it in the predicted top N for this user?\n",
        "        hitRank = 0\n",
        "        rank = 0\n",
        "        for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "            rank = rank + 1\n",
        "            if (int(leftOutMovieID) == movieID):\n",
        "                hitRank = rank\n",
        "                break\n",
        "        if (hitRank > 0) :\n",
        "            summation += 1.0 / hitRank\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    return summation / total"
      ],
      "metadata": {
        "id": "cQEUjutD8efg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def UserCoverage(topNPredicted, numUsers, ratingThreshold=0):\n",
        "    hits = 0\n",
        "    for userID in topNPredicted.keys():\n",
        "        hit = False\n",
        "        for movieID, predictedRating in topNPredicted[userID]:\n",
        "            if (predictedRating >= ratingThreshold):\n",
        "                hit = True\n",
        "                break\n",
        "        if (hit):\n",
        "            hits += 1\n",
        "\n",
        "    return hits / numUsers"
      ],
      "metadata": {
        "id": "isKrl1kSPf7K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Diversity(topNPredicted, simsAlgo):\n",
        "    n = 0\n",
        "    total = 0\n",
        "    simsMatrix = simsAlgo.compute_similarities()\n",
        "    for userID in topNPredicted.keys():\n",
        "        pairs = itertools.combinations(topNPredicted[userID], 2)\n",
        "        for pair in pairs:\n",
        "            movie1 = pair[0][0]\n",
        "            movie2 = pair[1][0]\n",
        "            innerID1 = simsAlgo.trainset.to_inner_iid(str(movie1))\n",
        "            innerID2 = simsAlgo.trainset.to_inner_iid(str(movie2))\n",
        "            similarity = simsMatrix[innerID1][innerID2]\n",
        "            total += similarity\n",
        "            n += 1\n",
        "\n",
        "    S = total / n\n",
        "    return (1-S)"
      ],
      "metadata": {
        "id": "huESUB5XU6YG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Novelty(topNPredicted, rankings):\n",
        "    n = 0\n",
        "    total = 0\n",
        "    for userID in topNPredicted.keys():\n",
        "        for rating in topNPredicted[userID]:\n",
        "            movieID = rating[0]\n",
        "            rank = rankings[movieID]\n",
        "            total += rank\n",
        "            n += 1\n",
        "    return total / n"
      ],
      "metadata": {
        "id": "C_ppJmfAVIzZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(predictions, algo, train_loocv, test_loocv, bigTestSet, n, fullTrainSet, fbigTestSet, rankings):\n",
        "    metrics = {}\n",
        "    # Evaluating accuracy of model\n",
        "    metrics[\"RMSE\"] = accuracy.rmse(predictions, verbose=False)\n",
        "    metrics[\"MAE\"] = accuracy.mae(predictions, verbose=False)\n",
        "    \n",
        "    #Evaluating  top-N recommendations\n",
        "    # Hit rate\n",
        "    # Train model without left-out ratings\n",
        "    algo.fit(train_loocv)\n",
        "    # Predict ratings for left-out ratings only\n",
        "    leftOutPredictions = algo.test(test_loocv)\n",
        "    # Predict all ratings that are not in the training set\n",
        "    allPredictions = algo.test(bigTestSet) \n",
        "    # Compute top N recs for each user\n",
        "    topNpredicted = getTopN(allPredictions, n)\n",
        "    metrics[\"HR\"] = hitRate(topNPredicted, leftOutPredictions)\n",
        "    \n",
        "    # Cumulative hit rate\n",
        "    metrics[\"cHR\"] = CumulativeHitRate(topNPredicted, leftOutPredictions, 4.0)\n",
        "\n",
        "    # Average reciprocal hit rank\n",
        "    metrics[\"ARHR\"] = AverageReciprocalHitRank(topNPredicted, leftOutPredictions)\n",
        "    \n",
        "    # Coverage\n",
        "    # Compute complete recommendations, no hold outs\n",
        "    algo.fit(fullTrainSet)\n",
        "    allPredictions = algo.test(fbigTestSet)\n",
        "    topNpredicted = getTopN(allPredictions, n)\n",
        "    metrics[\"Coverage\"] = UserCoverage(topNPredicted, fullTrainSet.n_users, ratingThreshold=4.0)\n",
        "    \n",
        "    # Diversity\n",
        "    # Compute item similarities so we can measure diversity later\n",
        "    sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
        "    simsAlgo = KNNBaseline(sim_options=sim_options)\n",
        "    simsAlgo.fit(fullTrainSet)\n",
        "    metrics[\"Diversity\"] = Diversity(topNPredicted, simsAlgo)\n",
        "    \n",
        "    # Novelty\n",
        "    metrics[\"Novelty\"] = Novelty(topNPredicted, rankings)\n",
        "    \n",
        "    \n",
        "    return metrics"
      ],
      "metadata": {
        "id": "IfdDl3VxVWpU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yit1o3OL_r3S"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "w_En6Z5n_r3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9869b21d-4d35-4124-9b09-155a159726bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ml-1m could not be found. Do you want to download it? [Y/n] Y\n",
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-1m.zip...\n",
            "Done! Dataset ml-1m has been saved to /root/.surprise_data/ml-1m\n"
          ]
        }
      ],
      "source": [
        "data = Dataset.load_builtin(name='ml-1m', prompt=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "6EkxxeQA_r3U"
      },
      "outputs": [],
      "source": [
        "# Standard train/test split. This will be used for the ratings prediction regression task\n",
        "trainSet, testSet = train_test_split(data, test_size=.25, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8M_rNg2_r3U"
      },
      "source": [
        "## SVD\n",
        "\n",
        "SVD decomposes a given matrix A into three matrices, U, S, and V, such that A = U * S * V^T, where U and V are orthogonal matrices, and S is a diagonal matrix with non-negative values on the diagonal, called the singular values.\n",
        "\n",
        "The U and V matrices in SVD represent the left and right singular vectors of the matrix A, respectively. These matrices contain the basis vectors that span the columns of A and capture the most significant patterns in the data. The S matrix contains the singular values of A, which provide a measure of the importance of each singular vector.\n",
        "\n",
        "In the context of recommender systems, SVD is used to decompose the user-item rating matrix into user and item matrices with lower dimensions. The lower-dimensional matrices are then used to predict missing ratings or recommend items to users. This is achieved by computing the dot product between the user and item matrices to obtain the predicted ratings.\n",
        "\n",
        "SVD has been shown to be an effective technique for handling the sparsity and scalability challenges in recommender systems. However, SVD can be computationally expensive for large matrices, and it may suffer from overfitting if not regularized properly. Therefore, there are several variants of SVD, such as Truncated SVD and Regularized SVD, which mitigate these issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dR4C5er2_r3U"
      },
      "outputs": [],
      "source": [
        "svd = SVD(random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svd.fit(trainSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOxVwhf_Ut9F",
        "outputId": "4b71ba11-bc52-4e26-8cf1-3671df3c0b1c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7ffa68375a90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5Z9bXlxN_r3U"
      },
      "outputs": [],
      "source": [
        "# List of predictions on testSet\n",
        "predictions = svd.test(testSet)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "WIpgJQrYwJG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Evaluating accuracy of model"
      ],
      "metadata": {
        "id": "hznhsMw1qld4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys8FPHTB_r3V",
        "outputId": "5155b380-1d07-4735-e177-3ef0717e2452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating accuracy of model...\n",
            "RMSE:  0.875453779882117\n",
            "MAE:  0.687012485376433\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nEvaluating accuracy of model...\")\n",
        "print(\"RMSE: \", accuracy.rmse(predictions, verbose=False))\n",
        "print(\"MAE: \", accuracy.mae(predictions, verbose=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "del trainSet\n",
        "del testSet\n",
        "del predictions\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm45FSl3k-Z5",
        "outputId": "04107707-9ff3-486c-b8a4-5893ccf24808"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Evaluating top-N recommendations"
      ],
      "metadata": {
        "id": "qGi6Cb59qr39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.1. Hit rate:\n",
        "See how often we recommended a movie the user actually rated\n",
        "\n",
        "    How to compute hit rate? \n",
        "\n",
        "    The inital dataset is a matrix (n_users x n_movies) of actual ratings and zeros (or NA) where. Each cell corresponds to a pair (user_id, movie_id).\n",
        "\n",
        "    Firstly, we split the data by seting aside one rating per user for testing (test_loocv) using leave-one-out cross-validation (LOOCV). All the other user's movies will be in the training set (train_loocv).\n",
        "\n",
        "    After training the model on the training set, predictions are made on the left-out movie in the test set. Then, all the missing ratings from the training set are predicted using the trained model.\n",
        "\n",
        "    Next, the top N recommendations are computed for each user. For every left-out movie in the test set, if that movie is present in the top N recommendations for the user, that is considered a hit.\n",
        "\n",
        "    Finally, the hit rate is calculated as the ratio of the number of hits to the total number of left-out movies.\n"
      ],
      "metadata": {
        "id": "0h-6eRrvwKIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.dataset import Trainset\n",
        "# Leave-one-out cross validation split. This will be used for hit-rate prediction\n",
        "# The split is performed by seting aside one rating per user for testing. All the other (user, movie) combos will be in the trainset\n",
        "# n_splits: number of folds\n",
        "LOOCV = LeaveOneOut(n_splits=1, random_state=1) # Cross-validation iterator where each user has exactly one rating in the testset.\n",
        "\n",
        "train_loocv, test_loocv = list(LOOCV.split(data))[0]"
      ],
      "metadata": {
        "id": "z69tjaLyj15J"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zIcOyEvxhDrG"
      },
      "outputs": [],
      "source": [
        "# Train model without left-out ratings\n",
        "svd.fit(train_loocv)\n",
        "# Predict ratings for left-out ratings only\n",
        "leftOutPredictions = svd.test(test_loocv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Lar_f6vehQL1"
      },
      "outputs": [],
      "source": [
        "# Build predictions for all ratings not in the training set\n",
        "# build_anti_testset: returns a list of ratings that are missing in the train_loocv \n",
        "bigTestSet = train_loocv.build_anti_testset()\n",
        "allPredictions = svd.test(bigTestSet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpiEy5mT_r3V",
        "outputId": "c0ff07f1-ea1d-4bb7-b746-13f144726a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hit Rate:  0.03360927152317881\n"
          ]
        }
      ],
      "source": [
        "# Compute top 10 recs for each user\n",
        "topNPredicted = getTopN(allPredictions, n=10)\n",
        "# See how often we recommended a movie the user actually rated\n",
        "print(\"\\nHit Rate: \", hitRate(topNPredicted, leftOutPredictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "del bigTestSet\n",
        "del train_loocv\n",
        "del test_loocv\n",
        "del allPredictions\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32ScGXbNnMYH",
        "outputId": "31fa04d5-4421-427f-e1a8-9ebf752fa53b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.2. Cumulative Hit Rate: \n",
        "see how often we recommended a movie the user actually liked\n",
        "\n",
        "    Hit rate, confined to ratings above a certain threshold. "
      ],
      "metadata": {
        "id": "Tj3rIK3T4GkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See how often we recommended a movie the user actually rated\n",
        "print(\"\\ncHR (Cumulative Hit Rate, rating >= 4): \", CumulativeHitRate(topNPredicted, leftOutPredictions, 4.0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQRaSUHR7ha_",
        "outputId": "f9ee7822-8335-49cb-e0cf-7039498c7b1d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "cHR (Cumulative Hit Rate, rating >= 4):  0.0509571313022378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.3. Average Reciprocal Hit Rank:\n",
        "    Hit rate that takes the ranking into account.\n"
      ],
      "metadata": {
        "id": "-gfCmuWzPDqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute ARHR\n",
        "print(\"\\nARHR (Average Reciprocal Hit Rank): \", AverageReciprocalHitRank(topNPredicted, leftOutPredictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mI9uNGx4KXv",
        "outputId": "c2454cba-7bab-4da2-d504-d3aa13d4c6fe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ARHR (Average Reciprocal Hit Rank):  0.012887036161042793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "del topNPredicted\n",
        "del leftOutPredictions\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcnC4BFDxDJ2",
        "outputId": "45044255-250a-4672-d085-f8dcf9c2f1e8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.4. Coverage:\n",
        "    What percentage of users have at least one \"good\" recommendation\n"
      ],
      "metadata": {
        "id": "NpWQm2-uPtZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare full dataset for training\n",
        "fullTrainSet = data.build_full_trainset()"
      ],
      "metadata": {
        "id": "-3UsQUt-yTQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nComputing complete recommendations, no hold outs...\")\n",
        "svd.fit(fullTrainSet)\n",
        "bigTestSet = fullTrainSet.build_anti_testset()\n",
        "allPredictions = svd.test(bigTestSet)\n",
        "topNPredicted = getTopN(allPredictions, n=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KImZDDOgQOmy",
        "outputId": "6927fd0d-5d95-46c9-f774-83dc9e144d7f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Computing complete recommendations, no hold outs...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print user coverage with a minimum predicted rating of 4.0:\n",
        "print(\"\\nUser coverage: \", UserCoverage(topNPredicted, fullTrainSet.n_users, ratingThreshold=4.0))\n"
      ],
      "metadata": {
        "id": "24jmRQSIP64R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ee9939-b0bb-4878-fe70-e1f90de155d5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User coverage:  0.9897350993377484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.5. Diversity"
      ],
      "metadata": {
        "id": "LklLau9AR_SR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nComputing item similarities so we can measure diversity later...\")\n",
        "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
        "simsAlgo = KNNBaseline(sim_options=sim_options)\n",
        "simsAlgo.fit(fullTrainSet)"
      ],
      "metadata": {
        "id": "UfCZ4Ys_QaXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17977d9-fa2e-475a-8ce5-6c74b5cdbc8d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Computing item similarities so we can measure diversity later...\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.knns.KNNBaseline at 0x7ffa37f5f790>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure diversity of recommendations:\n",
        "print(\"\\nDiversity: \", Diversity(topNPredicted, simsAlgo))"
      ],
      "metadata": {
        "id": "WddT2NN2SEYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "578c1512-561e-4c88-c792-d0972fe99a62"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "\n",
            "Diversity:  0.933834367587023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.6. Novelty"
      ],
      "metadata": {
        "id": "kkuejkaFSub-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "del fullTrainSet\n",
        "del allPredictions\n",
        "del bigTestSet\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nZMtOtMy1uA",
        "outputId": "179ed126-29be-4419-f4f6-b25cf120ff6b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute movie popularity ranks so we can measure novelty later\n",
        "rankings = getPopularityRanks(data.raw_ratings)"
      ],
      "metadata": {
        "id": "Vcs3DFW3YEe8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure novelty (average popularity rank of recommendations):\n",
        "print(\"\\nNovelty (average popularity rank): \", Novelty(topNPredicted, rankings))"
      ],
      "metadata": {
        "id": "FKMwHDmRSzIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a2eec3-63e7-4c84-b11c-dc4c4755730e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Novelty (average popularity rank):  643.175474968562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "del topNPredicted\n",
        "del rankings\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTQuxlR5odW-",
        "outputId": "35ea65c3-7ff7-4639-8bcb-e82f9ef9ae03"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwuCwLea_r3W"
      },
      "source": [
        "## SVD++\n",
        "\n",
        "The SVD++ algorithm, an extension of SVD taking into account implicit ratings."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svdpp = SVDpp(random_state=10)"
      ],
      "metadata": {
        "id": "w93iqhiPWRnY"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svdpp.fit(trainSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAOXY-DiX3Jc",
        "outputId": "79f8177c-f896-4bcb-c0fb-aaa25284bbf0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVDpp at 0x7ffa37f5fbb0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of predictions on testSet\n",
        "predictions = svdpp.test(testSet)"
      ],
      "metadata": {
        "id": "Aoz23wVqX4_3"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Evaluating accuracy of model"
      ],
      "metadata": {
        "id": "xmaRxNFnpKMc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67464f95-a725-40da-87cc-179de7293bc9",
        "id": "zT4quQtJpKMd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating accuracy of model...\n",
            "RMSE:  0.865609967139632\n",
            "MAE:  0.6755024733708137\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nEvaluating accuracy of model...\")\n",
        "print(\"RMSE: \", accuracy.rmse(predictions, verbose=False))\n",
        "print(\"MAE: \", accuracy.mae(predictions, verbose=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "del trainSet\n",
        "del testSet\n",
        "del predictions\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a66004b-17ed-4132-a5c9-d4d92409d67e",
        "id": "jcA7TYkzpKMe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Evaluating top-N recommendations"
      ],
      "metadata": {
        "id": "RTxDKhsBpjNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.1. Hit rate:\n",
        "See how often we recommended a movie the user actually rated\n",
        "\n",
        "    How to compute hit rate? \n",
        "\n",
        "    The inital dataset is a matrix (n_users x n_movies) of actual ratings and zeros (or NA) where. Each cell corresponds to a pair (user_id, movie_id).\n",
        "\n",
        "    Firstly, we split the data by seting aside one rating per user for testing (test_loocv) using leave-one-out cross-validation (LOOCV). All the other user's movies will be in the training set (train_loocv).\n",
        "\n",
        "    After training the model on the training set, predictions are made on the left-out movie in the test set. Then, all the missing ratings from the training set are predicted using the trained model.\n",
        "\n",
        "    Next, the top N recommendations are computed for each user. For every left-out movie in the test set, if that movie is present in the top N recommendations for the user, that is considered a hit.\n",
        "\n",
        "    Finally, the hit rate is calculated as the ratio of the number of hits to the total number of left-out movies.\n"
      ],
      "metadata": {
        "id": "pvJ2vaDRpjNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.dataset import Trainset\n",
        "# Leave-one-out cross validation split. This will be used for hit-rate prediction\n",
        "# The split is performed by seting aside one rating per user for testing. All the other (user, movie) combos will be in the trainset\n",
        "# n_splits: number of folds\n",
        "LOOCV = LeaveOneOut(n_splits=1, random_state=1) # Cross-validation iterator where each user has exactly one rating in the testset.\n",
        "\n",
        "train_loocv, test_loocv = list(LOOCV.split(data))[0]"
      ],
      "metadata": {
        "id": "gHwv0MBWpjNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G2IBWBmpjNM"
      },
      "outputs": [],
      "source": [
        "# Train model without left-out ratings\n",
        "svdpp.fit(train_loocv)\n",
        "# Predict ratings for left-out ratings only\n",
        "leftOutPredictions = svdpp.test(test_loocv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTELUQjvpjNM"
      },
      "outputs": [],
      "source": [
        "# Build predictions for all ratings not in the training set\n",
        "# build_anti_testset: returns a list of ratings that are missing in the train_loocv \n",
        "bigTestSet = train_loocv.build_anti_testset()\n",
        "allPredictions = svdpp.test(bigTestSet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08f7358-76e5-431d-f692-9b5cb4c64de4",
        "id": "84MX7YqnpjNM"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hit Rate:  0.03642384105960265\n"
          ]
        }
      ],
      "source": [
        "# Compute top 10 recs for each user\n",
        "topNPredicted = getTopN(allPredictions, n=10)\n",
        "# See how often we recommended a movie the user actually rated\n",
        "print(\"\\nHit Rate: \", hitRate(topNPredicted, leftOutPredictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "del bigTestSet\n",
        "del train_loocv\n",
        "del test_loocv\n",
        "del allPredictions\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d6ace7-8508-4833-953a-e1c4671ff942",
        "id": "57GIXjMypjNM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.2. Cumulative Hit Rate: \n",
        "see how often we recommended a movie the user actually liked\n",
        "\n",
        "    Hit rate, confined to ratings above a certain threshold. "
      ],
      "metadata": {
        "id": "5Sof-9-ApjNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See how often we recommended a movie the user actually rated\n",
        "print(\"\\ncHR (Cumulative Hit Rate, rating >= 4): \", CumulativeHitRate(topNPredicted, leftOutPredictions, 4.0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91967b73-738e-487d-bf9d-484b6e61bc1b",
        "id": "tCTah2R3pjNM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "cHR (Cumulative Hit Rate, rating >= 4):  0.0509571313022378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.3. Average Reciprocal Hit Rank:\n",
        "    Hit rate that takes the ranking into account.\n"
      ],
      "metadata": {
        "id": "uKIb1dKSpjNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute ARHR\n",
        "print(\"\\nARHR (Average Reciprocal Hit Rank): \", AverageReciprocalHitRank(topNPredicted, leftOutPredictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ce0d92-8dcc-41ad-e926-adec672a5dfb",
        "id": "DBLxOcyBpjNN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ARHR (Average Reciprocal Hit Rank):  0.012887036161042793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.4. Coverage:\n",
        "    What percentage of users have at least one \"good\" recommendation\n"
      ],
      "metadata": {
        "id": "sEaFSwp2pjNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nComputing complete recommendations, no hold outs...\")\n",
        "svd.fit(fullTrainSet)\n",
        "bigTestSet = fullTrainSet.build_anti_testset()\n",
        "allPredictions = svd.test(bigTestSet)\n",
        "topNPredicted = getTopN(allPredictions, n=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae89700-a5cf-4e88-aeef-1149e517c7b3",
        "id": "CBvvOLyNpjNN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Computing complete recommendations, no hold outs...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print user coverage with a minimum predicted rating of 4.0:\n",
        "print(\"\\nUser coverage: \", UserCoverage(topNPredicted, fullTrainSet.n_users, ratingThreshold=4.0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b755626a-0efe-4de6-afe4-978d2ccb87bc",
        "id": "HR4kcW3KpjNN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User coverage:  0.9897350993377484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.5. Diversity"
      ],
      "metadata": {
        "id": "o6n0Lco0pjNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure diversity of recommendations:\n",
        "print(\"\\nDiversity: \", Diversity(topNPredicted, simsAlgo))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85cb5838-e6bb-4635-86d7-4ca6bf3ab632",
        "id": "JMNSqr38pjNN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "\n",
            "Diversity:  0.933834367587023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.6. Novelty"
      ],
      "metadata": {
        "id": "sTGsd1dNpjNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure novelty (average popularity rank of recommendations):\n",
        "print(\"\\nNovelty (average popularity rank): \", Novelty(topNPredicted, rankings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9681c0b1-4eb6-4d6a-f419-99825c437983",
        "id": "-LYmM27TpjNN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Novelty (average popularity rank):  643.175474968562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "del bigTestSet\n",
        "del allPredictions\n",
        "del topNPredicted\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d6ad15-5afc-4501-ce06-f03455a4e47d",
        "id": "HJLyl7hKpjNO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "696"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "The results showed that SVC++ is a bit better that SVD in terms of accuracy and in terms of quality of recommendations as well.\n",
        "I'am pretty sure we could get better results with some hyperparameters tuning, but SVD and SVD++ can be time-consuming and computationally expensive on a large datasets (as movielens-20m), let alone evaluating all the metrics discussed above.\n",
        "\n",
        "Here are some downsides of SVD and SVD++ i've found:\n",
        "\n",
        "* SVD and SVD++ can be computationally expensive: The calculation of SVD and SVD++ involves computing a large number of matrix operations, which can be time-consuming and computationally expensive, especially for large matrices.\n",
        "\n",
        "* SVD and SVD++ may not work well with sparse matrices: Both SVD and SVD++ assume that the input matrix is dense and complete, which means that there are no missing values. In real-world applications, however, input matrices are often sparse, and SVD and SVD++ may not work well with incomplete data.\n",
        "\n",
        "* SVD and SVD++ can suffer from overfitting: SVD and SVD++ are prone to overfitting, especially when the input matrix is noisy or when the number of latent factors is too high. This can result in poor performance on unseen data.\n",
        "\n",
        "* SVD and SVD++ may not capture non-linear relationships: Both SVD and SVD++ assume that the relationships between the items and users are linear. However, in many real-world scenarios, the relationships may be non-linear, and SVD and SVD++ may not be able to capture them effectively.\n",
        "\n",
        "* SVD++ requires additional user and item features: SVD++ requires additional user and item features, which may not always be available or may be difficult to obtain. Without these features, the performance of SVD++ can be limited."
      ],
      "metadata": {
        "id": "XMi0e1JKVydT"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}